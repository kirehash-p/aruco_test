<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>ArUco Marker Overlay with OpenCV.js</title>
  <style>
    body { margin: 0; overflow: hidden; }
    video, img { display: none; }
    #canvasOutput { 
      position: absolute; 
      top: 0; left: 0; 
      width: 100%; height: 100%; 
      object-fit: contain;
    }
    #controls {
      position: absolute; bottom: 10px; left: 10px;
      background: rgba(0,0,0,0.7); color: white;
      padding: 10px; border-radius: 5px; z-index: 1000;
    }
    #controls label { display: block; margin: 5px 0; }
    #controls select, #controls input { margin-left: 10px; }
    #fileUpload { margin-top: 10px; }
  </style>
</head>
<body>
  <video id="videoInput" playsinline autoplay></video>
  <canvas id="canvasOutput"></canvas>
  <img id="defaultImage" src="assets/default.jpg" alt="default">
  <img id="uploadedImage" alt="uploaded">

  <div id="controls">
    <label>
      カメラ選択:
      <select id="cameraSelect"></select>
    </label>
    <label>
      合成画像:
      <select id="overlaySelect">
        <option value="defaultImage">デフォルト</option>
        <option value="uploadedImage">アップロード画像</option>
      </select>
    </label>
    <label>
      <input type="checkbox" id="showMarkers" checked>
      マーカー枠を表示
    </label>
    <div id="fileUpload">
      <label>
        画像をアップロード:
        <input type="file" id="imageInput" accept="image/*">
      </label>
    </div>
  </div>

  <script>
    async function launchApp() {
      console.log('▶ Module.onRuntimeInitialized');
      if (cv instanceof Promise) {
        console.log('⏳ Awaiting cv promise…');
        cv = await cv;
      }
      console.log('✅ cv promise resolved');
      startProcessing();
    }
  </script>

  <script>
    var Module = {
      locateFile: path => path.endsWith('.wasm') ? 'js/opencv_js.wasm' : path,
      onRuntimeInitialized: launchApp
    };
  </script>

  <script src="js/loader.js"></script>
  <script src="js/opencv.js"></script>

  <script>
    async function startProcessing() {
      console.log('▶ startProcessing()');
      const video         = document.getElementById('videoInput');
      const canvas        = document.getElementById('canvasOutput');
      const ctx           = canvas.getContext('2d');
      const cameraSelect  = document.getElementById('cameraSelect');
      const overlaySelect = document.getElementById('overlaySelect');
      const showMarkers   = document.getElementById('showMarkers');
      const imageInput    = document.getElementById('imageInput');
      const uploadedImage = document.getElementById('uploadedImage');

      let currentStream = null;
      let isProcessing  = false;
      let frameSkipCount = 0, FRAME_SKIP = 1;

      // 1) 初回に全カメラ許可を取ってラベル取得
      try {
        const tmpStream = await navigator.mediaDevices.getUserMedia({ video: true });
        tmpStream.getTracks().forEach(t => t.stop());
      } catch (err) {
        console.warn('初回カメラ許可取得に失敗:', err);
      }

      // 2) 許可後にデバイス一覧を取得してセレクトを作成
      const devices = await navigator.mediaDevices.enumerateDevices();
      const cams = devices.filter(d => d.kind === 'videoinput');
      cams.forEach((cam, i) => {
        const opt = document.createElement('option');
        opt.value = cam.deviceId;
        opt.text  = cam.label || `Camera ${i+1}`;
        cameraSelect.appendChild(opt);
      });

      // 3) セレクト変更で都度許可＆起動
      cameraSelect.addEventListener('change', () => {
        startCamera(cameraSelect.value);
      });

      // 4) 最初のカメラを起動
      if (cams.length) startCamera(cams[0].deviceId);

      // カメラ起動関数（deviceId指定で都度許可ダイアログが出る）
      function startCamera(deviceId) {
        if (currentStream) {
          currentStream.getTracks().forEach(t => t.stop());
        }
        navigator.mediaDevices.getUserMedia({
          video: { deviceId: { exact: deviceId } },
          audio: false
        })
        .then(stream => {
          console.log('✔ getUserMedia success:', deviceId);
          currentStream = stream;
          video.srcObject  = stream;
        })
        .catch(err => console.error('✖ getUserMedia error:', err));
      }

      // アップロード画像取得
      imageInput.addEventListener('change', e => {
        const file = e.target.files[0];
        if (file) {
          const reader = new FileReader();
          reader.onload = ev => uploadedImage.src = ev.target.result;
          reader.readAsDataURL(file);
        }
      });

      video.addEventListener('loadedmetadata', () => {
        canvas.width  = video.videoWidth;
        canvas.height = video.videoHeight;

        // OpenCV Mat 準備
        let src  = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
        let dst  = new cv.Mat(video.videoHeight, video.videoWidth, cv.CV_8UC4);
        let gray = new cv.Mat();
        let perspectiveMatrix = new cv.Mat();
        let warpedOverlay     = new cv.Mat();

        const dictionary     = cv.getPredefinedDictionary(cv.DICT_4X4_50);
        const detectorParams = new cv.aruco_DetectorParameters();
        const refineParams   = new cv.aruco_RefineParameters(10.0, 3.0, true);
        const detector       = new cv.aruco_ArucoDetector(dictionary, detectorParams, refineParams);

        function processFrame() {
          try {
            if (frameSkipCount < FRAME_SKIP) {
              frameSkipCount++;
              requestAnimationFrame(processFrame);
              return;
            }
            frameSkipCount = 0;
            if (isProcessing) {
              requestAnimationFrame(processFrame);
              return;
            }
            isProcessing = true;

            ctx.drawImage(video, 0, 0);
            let imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
            src.data.set(imageData.data);

            cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
            let corners = new cv.MatVector();
            let ids     = new cv.Mat();
            detector.detectMarkers(gray, corners, ids);

            src.copyTo(dst);

            if (ids.rows > 0) {
              const overlayEl = document.getElementById(overlaySelect.value);
              let overlay = cv.imread(overlayEl);

              let sorted = [];
              for (let i = 0; i < ids.rows; i++) sorted.push({id: ids.data32S[i], index: i});
              sorted.sort((a,b)=>a.id-b.id);

              if (ids.rows >= 4) {
                let pts = [], ok = true;
                for (let id=0; id<4; id++){
                  let f = sorted.find(o=>o.id===id);
                  if (!f) { ok=false; break; }
                  pts.push(corners.get(f.index));
                }
                if (ok) {
                  const srcTri = cv.matFromArray(4,1,cv.CV_32FC2,[
                    0,0,
                    overlay.cols,0,
                    overlay.cols,overlay.rows,
                    0,overlay.rows
                  ]);
                  const dstTri = cv.matFromArray(4,1,cv.CV_32FC2,[
                    pts[0].data32F[0], pts[0].data32F[1],
                    pts[1].data32F[2], pts[1].data32F[3],
                    pts[2].data32F[4], pts[2].data32F[5],
                    pts[3].data32F[6], pts[3].data32F[7]
                  ]);
                  perspectiveMatrix = cv.getPerspectiveTransform(srcTri, dstTri);
                  cv.warpPerspective(overlay, warpedOverlay, perspectiveMatrix,
                                     new cv.Size(dst.cols, dst.rows),
                                     cv.INTER_LINEAR, cv.BORDER_CONSTANT, new cv.Scalar());
                  let mask = new cv.Mat();
                  let rgba = new cv.MatVector();
                  cv.split(warpedOverlay, rgba);
                  if (rgba.size()>3) mask = rgba.get(3);
                  else {
                    mask = new cv.Mat(warpedOverlay.rows, warpedOverlay.cols, cv.CV_8UC1, new cv.Scalar(255));
                    let black = new cv.Mat();
                    cv.cvtColor(warpedOverlay, black, cv.COLOR_RGBA2GRAY);
                    cv.threshold(black, black, 1, 255, cv.THRESH_BINARY);
                    cv.bitwise_and(mask, black, mask);
                    black.delete();
                  }
                  warpedOverlay.copyTo(dst, mask);
                  mask.delete(); rgba.delete();
                  srcTri.delete(); dstTri.delete();
                }
              }

              if (showMarkers.checked) {
                for (let i=0; i<corners.size(); i++){
                  let c = corners.get(i);
                  let id = ids.data32S[i];
                  for (let j=0; j<4; j++){
                    let x1=c.data32F[j*2], y1=c.data32F[j*2+1];
                    let x2=c.data32F[((j+1)%4)*2], y2=c.data32F[((j+1)%4)*2+1];
                    cv.line(dst, new cv.Point(x1,y1), new cv.Point(x2,y2), new cv.Scalar(0,255,0,255),2);
                  }
                  let cx=(c.data32F[0]+c.data32F[2]+c.data32F[4]+c.data32F[6])/4;
                  let cy=(c.data32F[1]+c.data32F[3]+c.data32F[5]+c.data32F[7])/4;
                  cv.putText(dst, id.toString(), new cv.Point(cx,cy),
                             cv.FONT_HERSHEY_SIMPLEX,1,new cv.Scalar(255,0,0,255),2);
                }
              }
              overlay.delete();
            }

            cv.imshow('canvasOutput', dst);
            corners.delete(); ids.delete();
          } catch (e) {
            console.error('processFrame error:', e);
          }
          isProcessing = false;
          requestAnimationFrame(processFrame);
        }

        requestAnimationFrame(processFrame);
      });
    }
  </script>
</body>
</html>
